{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First object condensation model training\n",
    "\n",
    "* **Requirements*: You need to have graphs constructed, e.g., with `010_build_graphs.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from gnn_tracking.postprocessing.dbscanscanner import dbscan_scan\n",
    "\n",
    "from gnn_tracking.models.track_condensation_networks import GraphTCN\n",
    "from gnn_tracking.training.tcn_trainer import TCNTrainer\n",
    "from gnn_tracking.metrics.losses import (\n",
    "    EdgeWeightFocalLoss,\n",
    "    PotentialLoss,\n",
    "    BackgroundLoss,\n",
    ")\n",
    "from gnn_tracking.utils.loading import get_loaders, TrackingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/homes/zque/ws/CERN/gnn-tracking/data/graphs\n"
     ]
    }
   ],
   "source": [
    "data_path = Path.home() / \"ws/CERN/gnn-tracking/data\" \n",
    "graph_dir = data_path / \"graphs\"\n",
    "print(graph_dir)\n",
    "assert graph_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[23:44:41] INFO: DataLoader will load 9 graphs (out of 10 available).\u001b[0m\n",
      "\u001b[36m[23:44:41] DEBUG: First graph is /homes/zque/ws/CERN/gnn-tracking/data/graphs/data2800_s0.pt, last graph is /homes/zque/ws/CERN/gnn-tracking/data/graphs/data2800_s16.pt\u001b[0m\n",
      "\u001b[32m[23:44:41] INFO: DataLoader will load 1 graphs (out of 10 available).\u001b[0m\n",
      "\u001b[36m[23:44:41] DEBUG: First graph is /homes/zque/ws/CERN/gnn-tracking/data/graphs/data2800_s17.pt, last graph is /homes/zque/ws/CERN/gnn-tracking/data/graphs/data2800_s17.pt\u001b[0m\n",
      "\u001b[36m[23:44:41] DEBUG: Parameters for data loader 'train': {'batch_size': 1, 'num_workers': 1, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x7f60f438cc10>, 'pin_memory': True, 'shuffle': None}\u001b[0m\n",
      "\u001b[36m[23:44:41] DEBUG: Parameters for data loader 'val': {'batch_size': 1, 'num_workers': 1, 'sampler': None, 'pin_memory': True, 'shuffle': False}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"train\": TrackingDataset(graph_dir, stop=9),\n",
    "    \"val\": TrackingDataset(graph_dir, start=9, stop=10),\n",
    "}\n",
    "loaders = get_loaders(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_functions = {\n",
    "    \"edge\": (EdgeWeightFocalLoss(gamma=5, alpha=0.95), 500.0),\n",
    "    \"potential\": (PotentialLoss(q_min=0.01), {\"attractive\": 500, \"repulsive\": 5}),\n",
    "    \"background\": (BackgroundLoss(sb=1), 0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values after the loss functions are the loss weights. The potential loss is a special case, because it returns a dictionary two values: `attractive` and `repulsive`. Therefore, there are also two loss weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphTCN(\n",
    "    node_indim=datasets[\"train\"].num_node_features,\n",
    "    edge_indim=datasets[\"train\"].num_edge_features,\n",
    "    h_dim=10,\n",
    "    e_dim=10,\n",
    "    L_ec=5,\n",
    "    L_hc=2,\n",
    "    h_outdim=10,\n",
    "    hidden_dim=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_functions = {\"dbscan\": dbscan_scan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[23:45:01 TCNTrainer] INFO: Using device cuda\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "trainer = TCNTrainer(\n",
    "    model=model,\n",
    "    loaders=loaders,\n",
    "    loss_functions=loss_functions,\n",
    "    lr=0.005,\n",
    "    cluster_functions=clustering_functions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/zque/ws/anaconda3/envs/gnn-tracking/lib/python3.10/site-packages/torch_geometric/data/collate.py:145: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = elem.storage()._new_shared(numel)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 3, in _binary_focal_loss\n\ndef mul(a : float, b : Tensor) -> Tensor:\n  return b * a\n         ~~~~~ <--- HERE\ndef add(a : float, b : Tensor) -> Tensor:\n  return b + a\nRuntimeError: Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:609\u001b[0m, in \u001b[0;36mTCNTrainer.train\u001b[0;34m(self, epochs, max_batches)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeyboard interrupt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:576\u001b[0m, in \u001b[0;36mTCNTrainer.step\u001b[0;34m(self, max_batches)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    575\u001b[0m timer \u001b[38;5;241m=\u001b[39m Timer()\n\u001b[0;32m--> 576\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m train_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_test_during_training:\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:356\u001b[0m, in \u001b[0;36mTCNTrainer.train_step\u001b[0;34m(self, max_batches)\u001b[0m\n\u001b[1;32m    354\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_preproc(data)\n\u001b[1;32m    355\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model(data)\n\u001b[0;32m--> 356\u001b[0m batch_loss, batch_losses, loss_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_losses\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_output\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    360\u001b[0m batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/training/tcn_trainer.py:242\u001b[0m, in \u001b[0;36mTCNTrainer.get_batch_losses\u001b[0;34m(self, model_output)\u001b[0m\n\u001b[1;32m    238\u001b[0m weights \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, (loss_func, these_weights) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_functions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# We need to unpack depending on whether the loss function returns a\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# single value, a list of values, or a dictionary of values.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     losses\u001b[38;5;241m.\u001b[39mupdate(unpack_loss_returns(key, \u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    243\u001b[0m     weights\u001b[38;5;241m.\u001b[39mupdate(unpack_loss_returns(key, these_weights))\n\u001b[1;32m    244\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(weights[k] \u001b[38;5;241m*\u001b[39m losses[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m losses)\n",
      "File \u001b[0;32m~/ws/anaconda3/envs/gnn-tracking/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/metrics/losses.py:114\u001b[0m, in \u001b[0;36mFalsifyLowPtEdgeWeightLoss.forward\u001b[0;34m(self, w, y, edge_index, pt, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, w: T, y: T, edge_index: T \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, pt: T \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    111\u001b[0m     y \u001b[38;5;241m=\u001b[39m falsify_low_pt_edges(\n\u001b[1;32m    112\u001b[0m         y\u001b[38;5;241m=\u001b[39my, edge_index\u001b[38;5;241m=\u001b[39medge_index, pt\u001b[38;5;241m=\u001b[39mpt, pt_thld\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_thld\n\u001b[1;32m    113\u001b[0m     )\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/metrics/losses.py:147\u001b[0m, in \u001b[0;36mEdgeWeightFocalLoss._forward\u001b[0;34m(self, w, y, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, w: T, y: T, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_focal_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43minpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ccnas2/bdp/zque/ws/CERN/gnn-tracking/gnn_tracking/src/gnn_tracking/metrics/losses.py:68\u001b[0m, in \u001b[0;36mbinary_focal_loss\u001b[0;34m(inpt, target, alpha, gamma, pos_weight)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(target)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# JIT compilation does not support optional arguments\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_focal_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43minpt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 3, in _binary_focal_loss\n\ndef mul(a : float, b : Tensor) -> Tensor:\n  return b * a\n         ~~~~~ <--- HERE\ndef add(a : float, b : Tensor) -> Tensor:\n  return b + a\nRuntimeError: Expected a proper Tensor but got None (or an undefined Tensor in C++) for argument #0 'self'\n"
     ]
    }
   ],
   "source": [
    "trainer.train(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
